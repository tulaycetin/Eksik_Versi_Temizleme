{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyzM2Y1dbDzYpAQr6JNHsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tulaycetin/Eksik_Versi_Temizleme/blob/main/K_Means.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.experimental import enable_iterative_imputer  # IterativeImputer'ı etkinleştirir.\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Kaggle veri setini indir\n",
        "path = kagglehub.dataset_download(\"maxhorowitz/nflplaybyplay2009to2016\")\n",
        "filename = os.path.join(path, \"NFL Play by Play 2009-2017 (v4).csv\")\n"
      ],
      "metadata": {
        "id": "3nj7xXL5fOVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Veri setini yükleyelim (10000 örnek ile sınırlı)\n",
        "def load_data(filename, sample_size=10000):\n",
        "    data = []\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            try:\n",
        "                # Gerekli sütunları alıp uygun tipte kaydedelim\n",
        "                qtr = int(row['qtr'])\n",
        "                down = int(row['down'])\n",
        "                time_secs = float(row['TimeSecs'])\n",
        "                win_prob = float(row['Win_Prob'])\n",
        "                data.append([qtr, down, time_secs, win_prob])\n",
        "            except ValueError:\n",
        "                continue  # Hatalı satırları atla\n",
        "    # Rastgele örnek seç\n",
        "    data = random.sample(data, min(sample_size, len(data)))\n",
        "    return data"
      ],
      "metadata": {
        "id": "_xpvAypsfOSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # MICE dönüşümünü uygulama (Eksik verileri doldur)\n",
        "def apply_mice_imputation(data):\n",
        "    # Veriyi numpy dizisine dönüştür\n",
        "    data_np = np.array(data, dtype=float)\n",
        "\n",
        "    # MICE (Multiple Imputation by Chained Equations) ile eksik verileri doldur\n",
        "    imputer = IterativeImputer(max_iter=10, random_state=0)\n",
        "    data_imputed = imputer.fit_transform(data_np)  # Veriyi doldur\n",
        "    return data_imputed"
      ],
      "metadata": {
        "id": "X7XpTDvRfOP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN ile aykırı değerleri tespit etme\n",
        "def knn_outlier_removal(data, k=5, threshold=0.6):\n",
        "    # Veriyi numpy array olarak dönüştür\n",
        "    data_np = np.array(data)\n",
        "\n",
        "    # 2D şekil sağlamak için, her veri satırını düzgün şekilde hizalayalım\n",
        "    data_np = data_np.reshape(-1, len(data[0]))  # Veri kümesindeki her bir satır uzunluğu kadar\n",
        "\n",
        "    # KNN modelini fit et\n",
        "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(data_np)\n",
        "    distances, _ = nbrs.kneighbors(data_np)\n",
        "\n",
        "    # En yakın komşuların ortalama mesafesi\n",
        "    mean_distances = np.mean(distances[:, 1:], axis=1)  # İlk sütun kendisi olduğundan hariç tutulur\n",
        "    threshold_value = np.mean(mean_distances) + threshold * np.std(mean_distances)\n",
        "\n",
        "    # Aykırı olmayanları filtrele\n",
        "    filtered_data = [data[i] for i in range(len(data)) if mean_distances[i] <= threshold_value]\n",
        "    return filtered_data\n",
        "\n"
      ],
      "metadata": {
        "id": "7MMcts5efONc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Min-Max Normalizasyonu\n",
        "def normalize_data(data):\n",
        "    min_vals = [min(col) for col in zip(*data)]\n",
        "    max_vals = [max(col) for col in zip(*data)]\n",
        "    normalized_data = [\n",
        "        [(val - min_vals[i]) / (max_vals[i] - min_vals[i]) if max_vals[i] - min_vals[i] != 0 else 0\n",
        "         for i, val in enumerate(row)]\n",
        "        for row in data\n",
        "    ]\n",
        "    return normalized_data\n",
        "\n",
        "# Öklid Mesafesi Hesaplama\n",
        "def euclidean_distance(point1, point2):\n",
        "    return math.sqrt(sum((p1 - p2) ** 2 for p1, p2 in zip(point1, point2)))\n"
      ],
      "metadata": {
        "id": "v8fCJrRBfOK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Means Kümeleme Algoritması\n",
        "def k_means_clustering(data, k, max_iters=100):\n",
        "    if k > len(data):\n",
        "        k = len(data)  # Küme sayısını veri sayısına eşitle\n",
        "        print(f\"Veri kümesi büyüklüğünden dolayı k değeri {len(data)} olarak ayarlandı.\")\n",
        "\n",
        "    centroids = random.sample(data, k)\n",
        "    for _ in range(max_iters):\n",
        "        clusters = [[] for _ in range(k)]\n",
        "\n",
        "        # Her veri noktasını en yakın merkeze ata\n",
        "        for point in data:\n",
        "            distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
        "            cluster_index = distances.index(min(distances))\n",
        "            clusters[cluster_index].append(point)\n",
        "\n",
        "        # Yeni küme merkezlerini hesaplayalım\n",
        "        new_centroids = []\n",
        "        for cluster in clusters:\n",
        "            if cluster:\n",
        "                new_centroid = [sum(dim) / len(cluster) for dim in zip(*cluster)]\n",
        "            else:\n",
        "                all_points = [point for cluster in clusters for point in cluster]\n",
        "                max_dist_point = max(all_points, key=lambda p: sum(euclidean_distance(p, c) for c in centroids))\n",
        "                new_centroid = max_dist_point\n",
        "            new_centroids.append(new_centroid)\n",
        "\n",
        "        # Eğer merkezler değişmezse algoritma durur\n",
        "        if new_centroids == centroids:\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return clusters, centroids\n"
      ],
      "metadata": {
        "id": "1x2PXeRSfOIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Kümeleme sonuçlarını görselleştirme\n",
        "def plot_clusters(clusters, centroids):\n",
        "    colors = ['blue', 'green', 'orange', 'purple', 'cyan', 'magenta']\n",
        "    markers = ['o', 's', 'D', '^', 'v', '*']\n",
        "    for i, cluster in enumerate(clusters):\n",
        "        x_vals = [point[2] for point in cluster]\n",
        "        y_vals = [point[3] for point in cluster]\n",
        "        plt.scatter(x_vals, y_vals, color=colors[i % len(colors)], marker=markers[i % len(markers)], alpha=0.5, label=f'Küme {i+1}')\n",
        "\n",
        "    centroid_x = [centroid[2] for centroid in centroids]\n",
        "    centroid_y = [centroid[3] for centroid in centroids]\n",
        "    plt.scatter(centroid_x, centroid_y, color='red', marker='x', s=100, label='Centroids')\n",
        "\n",
        "    plt.xlabel('TimeSecs')\n",
        "    plt.ylabel('Win Probability')\n",
        "    plt.title('K-Means Kümeleme Sonuçları')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UgC93WRCfOFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ana Program\n",
        "data = load_data(filename, sample_size=10000)\n",
        "\n",
        "# 1) MICE ile eksik değer doldurma\n",
        "data_imputed = apply_mice_imputation(data)\n",
        "\n",
        "# 2) Normalizasyon (MICE sonrası)\n",
        "data_normalized = normalize_data(data_imputed)\n",
        "\n",
        "# 3) K-Means kümeleme (normalleştirilmiş veri)\n",
        "k = 5\n",
        "clusters, centroids = k_means_clustering(data_normalized, k)\n",
        "\n",
        "# İlk kümeleme sonuçlarını yazdır\n",
        "for i, cluster in enumerate(clusters):\n",
        "    print(f'Küme {i + 1}: {len(cluster)} veri noktası')\n",
        "print(\"İlk Küme Merkezleri:\", centroids)\n",
        "\n",
        "# İlk kümeleme görselleştirme\n",
        "plot_clusters(clusters, centroids)\n",
        "\n",
        "# 4) Aykırı değer temizleme (normalize edilmiş veri üzerinde)\n",
        "data_knn_filtered = knn_outlier_removal(data_normalized, k=5, threshold=0.6)\n",
        "\n",
        "# 5) Tekrar K-Means (aykırı değerler atıldıktan sonra)\n",
        "clusters, centroids = k_means_clustering(data_knn_filtered, k)\n",
        "\n",
        "# İkinci (temizlenmiş) kümeleme sonuçlarını yazdır\n",
        "for i, cluster in enumerate(clusters):\n",
        "    print(f'Küme {i + 1}: {len(cluster)} veri noktası')\n",
        "print(\"Aykırı Değer Temizlenmiş Küme Merkezleri:\", centroids)\n",
        "\n",
        "# İkinci kümeleme görselleştirme\n",
        "plot_clusters(clusters, centroids)\n",
        "\n"
      ],
      "metadata": {
        "id": "j3bASWT5BoTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oabk7nfABoQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66QI3tYDBoOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fr4-ve7YBoMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Z8pQfS5BoKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QlsQceuWBoIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7zOxUAlBoGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhmEgQoWBoDq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}